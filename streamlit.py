from openai import OpenAI
import streamlit as st
import re
from dotenv import load_dotenv
from langchain_text_splitters import CharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ì±„ìš© ë°ì´í„° íŒŒì¼ ì½ê¸°
with open('jobs.txt', encoding='utf-8') as f:
    file = f.read()

# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
chfile = file.replace('\n', '\n\n')

# í…ìŠ¤íŠ¸ ë¶„í• 
splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=400)
lines = splitter.split_text(chfile)

# OpenAI Embedding ëª¨ë¸ ì´ˆê¸°í™”
embeddings = OpenAIEmbeddings(model='text-embedding-3-small')

# FAISS ë²¡í„° DB ìƒì„±
db = FAISS.from_texts(texts=lines, embedding=embeddings)

# ê²€ìƒ‰ê¸° ì„¤ì •
retriever = db.as_retriever(search_kwargs={'k': 100})

# ì‹œìŠ¤í…œ ë©”ì‹œì§€ ë° Prompt í…œí”Œë¦¿
system_message = """
    ë„ˆëŠ” ì…ë ¥ëœ question ì†ì— í¬í•¨ëœ ì§ë¬´, ê²½ë ¥, ì„ í˜¸ ì§€ì—­ì— ë§ëŠ” ì±„ìš© ê³µê³ ë¥¼ ë‹¤ì„¯ ê°œì”© ì¶œë ¥í•˜ëŠ” íƒìƒ‰ AIì•¼.
    ê²€ìƒ‰ëœ contextë“¤ ì¤‘ ì…ë ¥ëœ ì§ë¬´ì™€ ê°™ì€ ì¹´í…Œê³ ë¦¬ì¸ ì±„ìš© ê³µê³ ë¥¼ ì°¾ì•„ì˜¤ë©´ ë¼.
    ê³µê³ ì´ë¦„ì— ì§ë¬´ê°€ ë“¤ì–´ê°€ëŠ” ê³µê³ ë¥¼ ìš°ì„ ìœ¼ë¡œ ì¶œë ¥í•˜ê³ , ê·¸ ì´ì™¸ì—ëŠ” ëœë¤ìœ¼ë¡œ ì¶œë ¥í•´ì¤˜.
    ë§Œì•½ ì‚¬ìš©ìê°€ ë” ë§ì€ ê³µê³ ë¥¼ í•„ìš”ë¡œ í•œë‹¤ë©´, ê°™ì€ ì¹´í…Œê³ ë¦¬ì—ì„œ ì´ì „ì— ë„¤ê°€ ê°€ì ¸ì˜¨ ê³µê³ ë“¤ì„ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ ê³µê³ ë“¤ ì¤‘ ë‹¤ì„¯ ê°œë¥¼ ë½‘ì•„ì„œ ê°€ì ¸ì™€ì„œ ì¶œë ¥í•´ì¤˜.
    ì¶œë ¥ í˜•ì‹ì€ í•˜ë‚˜ì˜ ê³µê³ ë§ˆë‹¤ íšŒì‚¬ì´ë¦„, ê³µê³ ì´ë¦„, URLë¥¼ ì¶œë ¥í•´ì£¼ë©´ ë¼.

    # context: {context}
"""

prompt = ChatPromptTemplate.from_messages([
    ('system', system_message),
    MessagesPlaceholder(variable_name='chat_history'),
    ('human', '{question}'),
])

# LLM ë° ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
llm = ChatOpenAI(model='gpt-4o-mini', temperature=0.1)
memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)

# ê³µê³  ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜
def extract_company_and_title(page_content):
    company_pattern = r"íšŒì‚¬ì´ë¦„: ([^,]+)"
    job_title_pattern = r"ê³µê³ ì´ë¦„: ([^,]+)"
    url_pattern = r"url: ([^,]+)"
    
    company_name = re.search(company_pattern, page_content)
    job_title = re.search(job_title_pattern, page_content)
    url = re.search(url_pattern, page_content)
    
    return company_name.group(1) if company_name else None, job_title.group(1) if job_title else None, url.group(1) if url else None

# ì±„ìš© ê³µê³  ê²€ìƒ‰ ë° ì¶œë ¥ í•¨ìˆ˜
def search_jobs_and_update_chat(question, start_index=0, limit=5):
    # FAISS ê²€ìƒ‰
    results = retriever.get_relevant_documents(question)

    # ì¤‘ë³µëœ ê²°ê³¼ ì œê±°
    displayed_results = st.session_state.get("displayed_results", [])
    new_results = [result for result in results if result not in displayed_results]

    # ìƒˆë¡­ê²Œ ì¶œë ¥í•  ê³µê³ 
    output = new_results[start_index:start_index + limit]
    job_messages = []

    for result in output:
        company_name, job_title, url = extract_company_and_title(result.page_content)
        if company_name and job_title and url:
            job_messages.append(f"- íšŒì‚¬ì´ë¦„: {company_name}, ê³µê³ ì´ë¦„: {job_title}, [URL]({url})")
    
    if job_messages:
        st.session_state["displayed_results"].extend(output)
        return "\n".join(job_messages)
    else:
        return "ë” ì´ìƒ í‘œì‹œí•  ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤."

# ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬ í•¨ìˆ˜
def process_user_question(question):
    context = "\n".join([result.page_content for result in retriever.get_relevant_documents(question)])
    
    chain = (
        RunnablePassthrough.assign(context=RunnableLambda(lambda _: context))
        | RunnablePassthrough.assign(chat_history=RunnableLambda(lambda _: memory.chat_memory.messages))  # ìˆ˜ì •ëœ ë¶€ë¶„
        | prompt
        | llm
        | StrOutputParser()
    )

    response = chain.invoke({"question": question})
    memory.save_context({"input": question}, {"output": response})
    return response

# Streamlit ì•± êµ¬ì„±
st.title("ğŸ’¬ Chatbot - ì±„ìš© ê³µê³  íƒìƒ‰ AI")
st.caption("LLM ë° FAISSë¥¼ í™œìš©í•œ ì±„ìš© ê³µê³  íƒìƒ‰")

# ì´ˆê¸° ë©”ì‹œì§€ ì„¤ì •
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."}]

if "displayed_results" not in st.session_state:
    st.session_state["displayed_results"] = []

# ì‚¬ì´ë“œë°”: ì¡°ê±´ ì„ íƒ
with st.sidebar:
    job_options = ['ë°ì´í„° ë¶„ì„ê°€', 'ë°ì´í„° ì—”ì§€ë‹ˆì–´', 'AI ê°œë°œì', 'ì±—ë´‡ ê°œë°œì', 
                   'í´ë¼ìš°ë“œ ì—”ì§€ë‹ˆì–´', 'API ê°œë°œì', 'ë¨¸ì‹ ëŸ¬ë‹ ì—”ì§€ë‹ˆì–´', 'ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸']
    exp_options = ['ì‹ ì…', 'ê²½ë ¥']
    loc_options = ['ì„œìš¸', 'ê²½ê¸°', 'ì¸ì²œ', 'ëŒ€ì „', 'ê´‘ì£¼', 'ëŒ€êµ¬', 'ìš¸ì‚°', 'ë¶€ì‚°', 'ê°•ì›', 
                   'ì„¸ì¢…', 'ì¶©ë¶', 'ì¶©ë‚¨', 'ì „ë¶', 'ì „ë‚¨', 'ê²½ë¶', 'ê²½ë‚¨', 'ì œì£¼', 'í•´ì™¸']

    selected_job = st.selectbox("ì§ë¬´ë¥¼ ì„ íƒí•˜ì„¸ìš”:", job_options, key="selected_job")
    selected_exp = st.selectbox("ì‹ ì…/ê²½ë ¥ì„ ì„ íƒí•˜ì„¸ìš”:", exp_options, key="selected_exp")
    selected_loc = st.selectbox("ì§€ì—­ì„ ì„ íƒí•˜ì„¸ìš”:", loc_options, key="selected_loc")

    if st.button("ì±„ìš© ê³µê³  ê²€ìƒ‰"):
        st.session_state["messages"].append({
            "role": "user",
            "content": f"ì œê°€ ì„ íƒí•œ ì§ë¬´ëŠ” {selected_job}, ê²½ë ¥ì€ {selected_exp}, ì§€ì—­ì€ {selected_loc}ì…ë‹ˆë‹¤."
        })
        question = f"{selected_loc}ì—ì„œ {selected_exp}ì„ ì±„ìš©í•˜ëŠ” {selected_job} ê³µê³  ì•Œë ¤ì¤˜"
        st.session_state["question"] = question

        # ì±„ìš© ê³µê³  ê²€ìƒ‰
        response = search_jobs_and_update_chat(question)
        st.session_state["messages"].append({"role": "assistant", "content": response})

# ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# "ë” ë³´ê¸°" ë²„íŠ¼
if "question" in st.session_state and len(st.session_state["displayed_results"]) > 0:
    if st.button("ë” ë³´ê¸°"):
        question = st.session_state["question"]
        response = search_jobs_and_update_chat(
            question,
            start_index=len(st.session_state["displayed_results"])
        )
        st.session_state["messages"].append({"role": "assistant", "content": response})

# ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥ ì²˜ë¦¬
user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
if user_input :
    st.session_state["messages"].append({"role": "user", "content": user_input})
    if "ë” ë³´ê¸°" not in user_input:  # ì¼ë°˜ ì§ˆë¬¸ ì²˜ë¦¬
        response = process_user_question(user_input)
    else:  # "ë” ë³´ê¸°" ìš”ì²­ ë¬´ì‹œ
        response = "í˜„ì¬ ë”ë³´ê¸°ëŠ” ë²„íŠ¼ìœ¼ë¡œë§Œ ì§€ì›ë©ë‹ˆë‹¤."
    st.session_state["messages"].append({"role": "assistant", "content": response})
