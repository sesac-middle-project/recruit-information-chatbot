{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for role: 머신러닝 엔지니어\n",
      "Fetching data for role: 데이터 엔지니어\n",
      "Fetching data for role: 데이터 사이언티스트\n",
      "Fetching data for role: 빅데이터 엔지니어\n",
      "Data saved to wanted_jobs.csv. Total records: 810\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "# 크롬 드라이버 설정\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "# 직무별 URL과 직무 이름 매핑\n",
    "categories = [\n",
    "    {\n",
    "        'role': '머신러닝 엔지니어',\n",
    "        'url': 'https://www.wanted.co.kr/wdlist/518/1634?country=kr&job_sort=job.recommend_order&years=-1&selected=1634&locations=all'\n",
    "    },\n",
    "    {\n",
    "        'role': '데이터 엔지니어',\n",
    "        'url': 'https://www.wanted.co.kr/wdlist/518/655?country=kr&job_sort=job.recommend_order&years=-1&selected=655&locations=all'\n",
    "    },\n",
    "    {\n",
    "        'role': '데이터 사이언티스트',\n",
    "        'url': 'https://www.wanted.co.kr/wdlist/518/1024?country=kr&job_sort=job.recommend_order&years=-1&selected=1024&locations=all'\n",
    "    },\n",
    "    {\n",
    "        'role': '빅데이터 엔지니어',\n",
    "        'url': 'https://www.wanted.co.kr/wdlist/518/1025?country=kr&job_sort=job.recommend_order&years=-1&selected=1025&locations=all'\n",
    "    }\n",
    "]\n",
    "\n",
    "# 모든 직무 데이터를 저장할 리스트\n",
    "all_job_data = []\n",
    "\n",
    "for category in categories:\n",
    "    print(f\"Fetching data for role: {category['role']}\")\n",
    "    driver.get(category['url'])\n",
    "    time.sleep(5)  # 페이지 로드 대기\n",
    "\n",
    "    # 스크롤 끝까지 내리기\n",
    "    scroll_pause_time = 2\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(scroll_pause_time)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # 공고 리스트 가져오기\n",
    "    try:\n",
    "        job_elements = wait.until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, '//*[@id=\"__next\"]/div[3]/div[2]/ul/li'))\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error locating job elements for {category['role']}: {e}\")\n",
    "        job_elements = []\n",
    "\n",
    "    # 공고 데이터 추출\n",
    "    for job_element in job_elements:\n",
    "        try:\n",
    "            job_title = job_element.find_element(By.XPATH, './div/a/div[2]/span[1]').text\n",
    "            company_name = job_element.find_element(By.XPATH, './div/a/div[2]/span[2]').text\n",
    "            location = job_element.find_element(By.XPATH, './div/a/div[2]/span[3]').text\n",
    "            job_url = job_element.find_element(By.XPATH, './div/a').get_attribute('href')\n",
    "\n",
    "            # 데이터 저장 (직무 추가)\n",
    "            all_job_data.append({\n",
    "                'role': category['role'],\n",
    "                'title': job_title,\n",
    "                'company': company_name,\n",
    "                'location': location,\n",
    "                'url': job_url\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting job data for {category['role']}: {e}\")\n",
    "\n",
    "# CSV 파일로 저장\n",
    "csv_file = 'wanted_jobs.csv'\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=['role', 'title', 'company', 'location', 'url'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(all_job_data)\n",
    "\n",
    "print(f\"Data saved to {csv_file}. Total records: {len(all_job_data)}\")\n",
    "\n",
    "# # 드라이버 종료\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        role                                     title  company  \\\n",
      "0  머신러닝 엔지니어  Sr. Machine Learning Engineer (HPCNT AI)   하이퍼커넥트   \n",
      "1  머신러닝 엔지니어              AI Research Engineer (2년 이상)  폴스타헬스케어   \n",
      "2  머신러닝 엔지니어                              멀티모달 AI 엔지니어       로민   \n",
      "3  머신러닝 엔지니어                                   AI 엔지니어     카이헬스   \n",
      "4  머신러닝 엔지니어                            AI Lead (5년이상)      비글즈   \n",
      "\n",
      "            location                                 url  \n",
      "0  서울 강남구 · 경력 3-13년  https://www.wanted.co.kr/wd/254260  \n",
      "1  서울 서초구 · 경력 2년 이상  https://www.wanted.co.kr/wd/254283  \n",
      "2  서울 서초구 · 경력 2-10년  https://www.wanted.co.kr/wd/254250  \n",
      "3  서울 강남구 · 경력 3년 이상  https://www.wanted.co.kr/wd/254173  \n",
      "4  경기 성남시 · 경력 5-15년  https://www.wanted.co.kr/wd/253998  \n",
      "총 데이터 수: 810\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 경로 (다운로드한 파일의 경로를 지정)\n",
    "file_path = 'wanted_jobs.csv'\n",
    "\n",
    "# CSV 파일 읽기\n",
    "jobs_data = pd.read_csv(file_path)\n",
    "\n",
    "# 데이터 확인\n",
    "print(jobs_data.head())  # 첫 몇 개의 행 출력\n",
    "print(f\"총 데이터 수: {len(jobs_data)}\")  # 데이터 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates:\n",
      "          role                                   title  \\\n",
      "2    머신러닝 엔지니어                            멀티모달 AI 엔지니어   \n",
      "10   머신러닝 엔지니어                                  AI 개발자   \n",
      "21   머신러닝 엔지니어                        머신러닝엔지니어 (3년 이상)   \n",
      "22   머신러닝 엔지니어               NLP Researcher / Engineer   \n",
      "31   머신러닝 엔지니어                      Senior ML Engineer   \n",
      "..         ...                                     ...   \n",
      "805  빅데이터 엔지니어                       Data Engineer(Jr)   \n",
      "806  빅데이터 엔지니어                          Data Scientist   \n",
      "807  빅데이터 엔지니어                                데이터 엔지니어   \n",
      "808  빅데이터 엔지니어                           Data Engineer   \n",
      "809  빅데이터 엔지니어  [인텔리전스랩스] 리서치 사이언티스트 (Computer Vision)   \n",
      "\n",
      "                       company            location  \\\n",
      "2                           로민   서울 서초구 · 경력 2-10년   \n",
      "10                       미니레코드    서울 송파구 · 경력 2-6년   \n",
      "21                        엠트리센   서울 금천구 · 경력 3년 이상   \n",
      "22   올거나이즈코리아(Allganize Korea)   서울 강남구 · 경력 1-10년   \n",
      "31                      바이온사이트  서울 성동구 · 경력 10년 이상   \n",
      "..                         ...                 ...   \n",
      "805                     데이터라이즈   서울 강남구 · 신입-경력 2년   \n",
      "806                        빅밸류    서울 중구 · 신입-경력 5년   \n",
      "807                         컬리    서울 강남구 · 경력 3-7년   \n",
      "808                       엑심베이   서울 구로구 · 신입-경력 2년   \n",
      "809               넥슨코리아(NEXON)   경기 성남시 · 경력 1-15년   \n",
      "\n",
      "                                    url  \n",
      "2    https://www.wanted.co.kr/wd/254250  \n",
      "10   https://www.wanted.co.kr/wd/254035  \n",
      "21   https://www.wanted.co.kr/wd/253132  \n",
      "22    https://www.wanted.co.kr/wd/93676  \n",
      "31   https://www.wanted.co.kr/wd/246633  \n",
      "..                                  ...  \n",
      "805  https://www.wanted.co.kr/wd/226473  \n",
      "806  https://www.wanted.co.kr/wd/242110  \n",
      "807  https://www.wanted.co.kr/wd/246566  \n",
      "808  https://www.wanted.co.kr/wd/234060  \n",
      "809  https://www.wanted.co.kr/wd/159531  \n",
      "\n",
      "[415 rows x 5 columns]\n",
      "Deduplicated data saved to: wanted_jobs_deduplicated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 중복값 식별\n",
    "duplicates = jobs_data[jobs_data.duplicated(subset=['title', 'company'], keep=False)]\n",
    "\n",
    "# 중복값 출력\n",
    "print(\"Duplicates:\")\n",
    "print(duplicates)\n",
    "\n",
    "# 중복값 제거\n",
    "jobs_data_deduplicated = jobs_data.drop_duplicates(subset=['title', 'company'], keep='first')\n",
    "\n",
    "# 중복 제거 후 데이터 저장\n",
    "deduplicated_file_path = 'wanted_jobs_deduplicated.csv'\n",
    "jobs_data_deduplicated.to_csv(deduplicated_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Deduplicated data saved to: {deduplicated_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "580"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the total number of rows in the deduplicated data\n",
    "total_rows_deduplicated = jobs_data_deduplicated.shape[0]\n",
    "\n",
    "total_rows_deduplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 데이터 개수: 580\n",
      "분류된 데이터가 저장되었습니다: wanted_jobs_categorized_roles_updated.csv\n",
      "\n",
      "업데이트된 역할별 데이터 개수:\n",
      "role\n",
      "AI 서비스 개발자    229\n",
      "데이터 분석가       132\n",
      "기타             62\n",
      "데이터 사이언티스트     47\n",
      "머신러닝 엔지니어      46\n",
      "데이터 엔지니어       40\n",
      "API 개발자        17\n",
      "클라우드 엔지니어       5\n",
      "챗봇 개발자          2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "file_path = 'wanted_jobs_deduplicated.csv'  # 파일 경로를 실제 경로로 변경하세요\n",
    "jobs_data = pd.read_csv(file_path)\n",
    "\n",
    "# 역할(직무)과 키워드 매핑 (기존 매핑 확장 가능)\n",
    "role_keywords = {\n",
    "    \"데이터 분석가\": [\n",
    "        ['데이터', '분석'],    \n",
    "        ['data', 'analyst'],  \n",
    "        ['db', '분석'],      \n",
    "        ['데이터', '애널리스트'],\n",
    "        ['buisness', 'analyst'],\n",
    "        ['analyst'],   \n",
    "        ['분석'],     \n",
    "        ['데이터 분석'], \n",
    "        ['data analyst'],\n",
    "        ['DB'],\n",
    "        ['데이터']\n",
    "    ],\n",
    "    \"데이터 엔지니어\": [\n",
    "        ['데이터', '엔지니어'],    \n",
    "        ['data', 'engineer'],  \n",
    "        ['db', '엔지니어'],      \n",
    "        ['db', 'engineer'],\n",
    "        ['dw'],\n",
    "        ['etl'],\n",
    "        ['spark']\n",
    "    ],\n",
    "    \"AI 서비스 개발자\": [\n",
    "        ['a', 'i', '개발'],\n",
    "        ['인공지능', '개발'],\n",
    "        ['a', 'i', '엔지니어'],\n",
    "        ['a', 'i', 'engineer'],\n",
    "        ['a', 'i', '연구'],\n",
    "        ['a', 'i', 'architect'],\n",
    "        ['딥', '러닝'],\n",
    "        ['deep', 'learning'],\n",
    "        ['machine', 'learning'],\n",
    "        ['a', 'i', 'researcher'],\n",
    "        ['a', 'i', 'solution'], \n",
    "        ['a', 'i', '전문가'],\n",
    "        ['생성'],\n",
    "        ['imaging'],\n",
    "        ['vision'],\n",
    "        ['nlp']\n",
    "    ],\n",
    "    \"챗봇 개발자\": [\n",
    "        ['챗봇', '개발'],\n",
    "        ['a', 'i', '개발'],\n",
    "        ['llm', '개발'],\n",
    "        ['react', '개발'], \n",
    "        ['프론트', '개발'],\n",
    "        ['bot']\n",
    "    ],\n",
    "    \"클라우드 엔지니어\": [\n",
    "        ['클라우드', '엔지니어'],\n",
    "        ['cloud', 'engineer'],\n",
    "        ['cloud', '엔지니어'],\n",
    "        ['클라우드', 'engineer'],\n",
    "        ['cloud', 'architect'],\n",
    "        ['클라우드', '아키텍트'],\n",
    "        ['클라우드', '운영'],\n",
    "        ['시스템', '엔지니어'],\n",
    "        ['클라우드', '개발'],\n",
    "        ['cloud', '개발'],\n",
    "        ['서버', '엔지니어'],\n",
    "        ['네트워크', '엔지니어'],\n",
    "        ['network', '엔지니어'],\n",
    "        ['네트워크', 'engineer'],\n",
    "        ['인프라', '엔지니어'],\n",
    "        ['cloud', 'sa'],\n",
    "        ['aws'],\n",
    "        ['azure'],\n",
    "        ['gcp']\n",
    "    ],\n",
    "    \"API 개발자\": [\n",
    "        ['API'], \n",
    "        ['rest'], \n",
    "        ['soap'], \n",
    "        ['graphql'], \n",
    "        ['api 개발'], \n",
    "        ['api 설계'], \n",
    "        ['endpoint'],\n",
    "        ['백엔드', '개발'],\n",
    "        ['Back-end'],\n",
    "        ['server']\n",
    "    ],\n",
    "    \"머신러닝 엔지니어\": [\n",
    "        ['머신러닝'], \n",
    "        ['Machine Learning'], \n",
    "        ['ML'], \n",
    "        ['tensorflow'], \n",
    "        ['scikit-learn'], \n",
    "        ['keras'], \n",
    "        ['모델링'], \n",
    "        ['머신러닝 개발'],\n",
    "        ['머신', '러닝', '엔지니어'],\n",
    "        ['machine', 'learning', 'engineer'],\n",
    "        ['ml', 'engineer'],\n",
    "        ['머신', '러닝', 'engineer'],\n",
    "        ['ml', '엔지니어'],\n",
    "        ['machine', 'learning', '엔지니어'],\n",
    "        ['머신', '러닝', '개발'],\n",
    "        ['ml', '개발'],\n",
    "        ['machine', 'learning', '개발'],\n",
    "        ['a', 'i', '개발'],\n",
    "        ['모델'],\n",
    "        ['predictive']\n",
    "    ],\n",
    "    \"데이터 사이언티스트\": [\n",
    "        ['사이언티스트'], \n",
    "        ['Scientist'], \n",
    "        ['Data Scientist'], \n",
    "        ['분석 모델'], \n",
    "        ['머신러닝'], \n",
    "        ['예측 분석'], \n",
    "        ['모델 평가'], \n",
    "        ['Data Science'],\n",
    "        ['statistics'],\n",
    "        ['R'],\n",
    "        ['python', 'analysis']\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 역할(직무)을 제목(title) 기준으로 분류하는 함수\n",
    "def assign_role(title):\n",
    "    \"\"\"\n",
    "    제목에 키워드가 포함되어 있는지 확인하고, 해당 역할을 반환.\n",
    "    키워드 그룹의 모든 키워드가 포함된 경우 해당 역할을 반환.\n",
    "    키워드가 포함되지 않은 경우 '기타' 반환.\n",
    "    \"\"\"\n",
    "    title = title.lower()  # 제목을 소문자로 변환\n",
    "    for role, keyword_groups in role_keywords.items():\n",
    "        for keywords in keyword_groups:\n",
    "            if all(keyword.lower() in title for keyword in keywords):  # 키워드를 소문자로 변환하여 비교\n",
    "                return role\n",
    "    return \"기타\"  # 어떤 역할에도 해당되지 않는 경우\n",
    "\n",
    "# 역할 분류 적용\n",
    "jobs_data['role'] = jobs_data['title'].apply(assign_role)\n",
    "\n",
    "# role이 \"기타\"인 데이터만 재분류\n",
    "misc_data = jobs_data[jobs_data['role'] == '기타']\n",
    "if not misc_data.empty:\n",
    "    jobs_data.loc[misc_data.index, 'role'] = misc_data['title'].apply(assign_role)\n",
    "\n",
    "# 결과를 새로운 CSV 파일로 저장\n",
    "output_file_path = 'wanted_jobs_categorized_roles_updated.csv'  # 결과를 저장할 파일 경로\n",
    "jobs_data.to_csv(output_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 데이터 요약 정보 출력\n",
    "role_counts = jobs_data['role'].value_counts()\n",
    "print(f\"총 데이터 개수: {len(jobs_data)}\")\n",
    "print(f\"분류된 데이터가 저장되었습니다: {output_file_path}\")\n",
    "print(\"\\n업데이트된 역할별 데이터 개수:\")\n",
    "print(role_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 데이터 개수: 580\n",
      "지역 및 경력 컬럼이 추가된 데이터가 저장되었습니다: wanted_jobs_categorized_with_location.csv\n"
     ]
    }
   ],
   "source": [
    "# 기존 데이터프레임에서 location 컬럼을 지역과 경력으로 나누기\n",
    "# location 컬럼이 \"경기 성남시 · 경력 7-15년\" 형식으로 되어 있다고 가정\n",
    "\n",
    "def split_location(location):\n",
    "    \"\"\"\n",
    "    location 컬럼을 '지역'과 '경력'으로 나누는 함수.\n",
    "    \"\"\"\n",
    "    if pd.isna(location):  # location 값이 NaN일 경우 처리\n",
    "        return pd.Series([None, None])  # NaN일 경우 둘 다 None 반환\n",
    "    parts = location.split(' · ')\n",
    "    if len(parts) == 2:\n",
    "        return pd.Series([parts[0].strip(), parts[1].strip()])  # ['지역', '경력'] 반환\n",
    "    elif len(parts) == 1:  # 경력이 없는 경우\n",
    "        return pd.Series([parts[0].strip(), None])  # 지역만 반환\n",
    "    return pd.Series([None, None])  # 예외 처리: None 반환\n",
    "\n",
    "# location 컬럼 분리 적용\n",
    "jobs_data[['지역', '경력']] = jobs_data['location'].apply(split_location)\n",
    "\n",
    "# 결과를 새로운 CSV 파일로 저장\n",
    "output_file_path = 'wanted_jobs_categorized_with_location.csv'  # 결과 저장 경로\n",
    "jobs_data.to_csv(output_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 데이터 요약 정보 출력\n",
    "print(f\"총 데이터 개수: {len(jobs_data)}\")\n",
    "print(f\"지역 및 경력 컬럼이 추가된 데이터가 저장되었습니다: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
